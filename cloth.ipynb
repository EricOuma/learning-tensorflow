{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/eric/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 21s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 6s 1us/step\n",
      "9\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.36444444 0.83111111\n",
      "  0.11555556 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00444444 0.         0.\n",
      "  0.00444444 0.         0.         0.79555556 1.06666667 1.05333333\n",
      "  1.13333333 1.06666667 0.61777778 0.36888889 0.28444444 0.19111111\n",
      "  0.26666667 0.24       0.         0.00444444]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00444444 0.         0.\n",
      "  0.00444444 0.         0.25777778 1.06222222 0.98666667 1.04\n",
      "  1.05777778 1.09333333 1.12       1.12888889 1.13333333 1.10222222\n",
      "  1.13333333 0.83111111 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00888889 0.01333333\n",
      "  0.         0.         0.86222222 1.06222222 1.00444444 1.05333333\n",
      "  1.04444444 1.03111111 1.02222222 1.04       1.04       1.03555556\n",
      "  1.10666667 0.76       0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00444444 0.00444444 0.\n",
      "  0.         0.04444444 1.13333333 1.00444444 1.07555556 1.06222222\n",
      "  1.05777778 1.06222222 1.06666667 1.06222222 1.07555556 1.05777778\n",
      "  1.10222222 0.85333333 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.76444444 1.08888889 1.01777778 1.06666667 1.07111111\n",
      "  1.06666667 1.07111111 1.08       1.08       1.07111111 1.00888889\n",
      "  1.11111111 0.92888889 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02666667 0.02222222 0.\n",
      "  0.27555556 1.13333333 1.02222222 1.04888889 1.06222222 1.07111111\n",
      "  1.07555556 1.07111111 1.07555556 1.07555556 1.05777778 1.05777778\n",
      "  1.07555556 1.12444444 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01333333 0.         0.\n",
      "  1.13333333 1.04444444 1.01333333 1.08444444 1.07111111 1.07111111\n",
      "  1.08444444 1.08       1.08       1.08444444 1.08       1.06222222\n",
      "  1.04444444 1.13333333 0.09777778 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.09333333\n",
      "  1.01333333 0.97777778 1.08888889 1.08       1.05333333 1.07111111\n",
      "  1.07555556 1.07555556 1.07555556 1.08       1.06222222 1.05333333\n",
      "  1.04444444 1.12444444 0.47111111 0.        ]\n",
      " [0.         0.         0.01333333 0.01777778 0.01777778 0.00888889\n",
      "  0.00444444 0.         0.         0.08       1.08       1.01333333\n",
      "  1.02666667 1.07111111 1.08       1.05333333 1.05777778 1.07555556\n",
      "  1.07111111 1.06666667 1.06666667 1.06666667 1.04444444 1.05333333\n",
      "  1.04888889 1.09333333 1.04       0.        ]\n",
      " [0.00444444 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09777778 1.13333333 1.05777778 1.00888889\n",
      "  1.05777778 1.06222222 1.05333333 1.07111111 1.07111111 1.05333333\n",
      "  1.04888889 1.05777778 1.06222222 1.06222222 1.06222222 1.06222222\n",
      "  1.06222222 1.05333333 1.13333333 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.11111111\n",
      "  0.36888889 0.74666667 1.13333333 1.         1.         1.04444444\n",
      "  1.01333333 1.02222222 1.00888889 1.         1.00888889 1.02666667\n",
      "  1.03111111 1.05333333 1.06666667 1.04888889 1.05777778 1.06222222\n",
      "  1.06222222 1.04444444 1.11555556 0.27555556]\n",
      " [0.         0.73333333 1.         0.97777778 0.99555556 1.13333333\n",
      "  1.13333333 1.03555556 1.01777778 0.99111111 1.00888889 1.01333333\n",
      "  1.02666667 1.03111111 1.04444444 1.05333333 1.03555556 1.02222222\n",
      "  1.01333333 1.02222222 1.03555556 1.03111111 1.04444444 1.03555556\n",
      "  1.04       1.04444444 1.13333333 0.25777778]\n",
      " [0.23111111 1.11555556 0.98222222 1.00444444 1.00888889 1.\n",
      "  1.         1.         1.00444444 1.00444444 1.         1.00888889\n",
      "  1.02666667 1.01777778 1.03111111 1.06222222 1.08888889 1.11111111\n",
      "  1.11555556 1.12       1.12888889 1.12888889 1.12       1.12888889\n",
      "  1.12       1.04444444 1.13333333 0.        ]\n",
      " [0.13777778 0.92444444 1.02222222 1.03555556 1.03555556 1.05333333\n",
      "  1.04888889 1.04888889 1.07111111 1.04444444 1.07111111 1.09777778\n",
      "  1.11555556 1.12888889 1.07555556 1.04888889 1.03555556 1.00888889\n",
      "  0.97333333 0.89777778 0.85777778 0.84       0.82666667 0.80444444\n",
      "  0.76       0.73333333 0.84444444 0.18666667]\n",
      " [0.34222222 0.88444444 0.76444444 0.83555556 0.88444444 0.89777778\n",
      "  0.96888889 0.97333333 0.97777778 1.01777778 1.04       0.98666667\n",
      "  0.94666667 0.92888889 0.92       0.93333333 0.90222222 0.81777778\n",
      "  0.67555556 0.76       0.73333333 0.72       0.72       0.74222222\n",
      "  0.74666667 0.69777778 0.85333333 0.34666667]\n",
      " [0.         0.2        0.44888889 0.62222222 0.70666667 0.77333333\n",
      "  0.80888889 0.82666667 0.82222222 0.83555556 0.86666667 0.87555556\n",
      "  0.83555556 0.77777778 0.59111111 0.31111111 0.08444444 0.\n",
      "  0.         0.92888889 1.02666667 0.96888889 0.98666667 0.99555556\n",
      "  1.00888889 0.96444444 1.01777778 0.41333333]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.00888889 0.10666667 0.16444444 0.2        0.14222222 0.08\n",
      "  0.04888889 0.         0.         0.         0.         0.\n",
      "  0.         0.32       0.22666667 0.23555556 0.16444444 0.15111111\n",
      "  0.12888889 0.13777778 0.02222222 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras #framework for defining a neural network\n",
    "import matplotlib.pyplot as plt #can be used to check how data looks like\n",
    "\n",
    "# if interested in stopping epoch when certain accuracy is reached\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.95):\n",
    "            print(\"\\nREached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# load the dataset\n",
    "mnist =  tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# getting the training values and testing values\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# normalisation - so as to work with values between 0 and 1\n",
    "training_images = training_images/225.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "plt.imshow(training_images[42])\n",
    "print(training_labels[42])\n",
    "print(training_images[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the model\n",
    "# the number of neurons in the last layer should match the number of classes you are classifying for\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), tf.keras.layers.Dense(256, activation=tf.nn.relu), tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 43s 713us/sample - loss: 0.4819 - acc: 0.8284\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 44s 727us/sample - loss: 0.3633 - acc: 0.8670\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 45s 742us/sample - loss: 0.3252 - acc: 0.8815\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 38s 632us/sample - loss: 0.3031 - acc: 0.8871\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 48s 793us/sample - loss: 0.2856 - acc: 0.8934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f76f57b1f60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling and training the model\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 444us/sample - loss: 0.3418 - acc: 0.8768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34180300602912905, 0.8768]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the model\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2160871e-05 5.7500916e-08 3.3555507e-06 1.7037431e-07 1.9697474e-05\n",
      " 3.0848688e-02 8.2944689e-06 1.0866456e-01 1.0187234e-05 8.6041284e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
